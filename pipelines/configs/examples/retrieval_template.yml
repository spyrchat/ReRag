# Template for Agent Retrieval Configuration
# Copy this file and modify for your specific retrieval needs

description: "Template for agent retrieval configuration"

# Main retrieval pipeline configuration
retrieval_pipeline:
  # Primary retriever configuration
  retriever:
    type: "hybrid"              # Options: dense, sparse, hybrid
    top_k: 20                   # Number of candidates to retrieve
    score_threshold: 0.01       # Minimum score threshold
    
    # For hybrid retrieval
    fusion_method: "rrf"        # Options: rrf, weighted_sum
    
    # Fusion parameters
    fusion:
      method: "rrf"             # Reciprocal rank fusion
      rrf_k: 60                 # RRF parameter (higher = more democratic)
      dense_weight: 0.7         # Weight for dense results (weighted_sum)
      sparse_weight: 0.3        # Weight for sparse results (weighted_sum)
    
    # Embedding configuration
    embedding:
      strategy: "hybrid"
      dense:
        provider: "google"
        model: "models/embedding-001"
        dimensions: 768
        api_key_env: "GOOGLE_API_KEY"
        batch_size: 32
        vector_name: "dense"
      sparse:
        provider: "sparse"
        model: "Qdrant/bm25"
        vector_name: "sparse"
    
    # Database configuration
    qdrant:
      collection_name: "your_collection_name"
      dense_vector_name: "dense"
      sparse_vector_name: "sparse"
    
    # Performance settings
    performance:
      lazy_initialization: true
      batch_size: 32
      enable_caching: true
      parallel_search: false

  # Processing stages (ordered pipeline)
  stages:
    # Stage 1: Primary retrieval (automatically added)
    - type: "retriever"
      name: "primary_retriever"
    
    # Stage 2: Score filtering
    - type: "score_filter"
      name: "score_filter"
      config:
        min_score: 0.01         # Filter out low-quality results
        max_results: 15         # Limit results for efficiency
    
    # Stage 3: Neural reranking
    - type: "reranker"
      name: "neural_reranker"
      config:
        model_type: "cross_encoder"
        model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
        top_k: 10              # Final number of results
        batch_size: 16         # Reranking batch size

# Global configuration (inherited by all components)
embedding_strategy: "hybrid"

# Quality and validation settings
quality:
  min_relevance_score: 0.1     # Minimum relevance threshold
  diversity_threshold: 0.8     # Avoid too similar results
  
# Performance optimization
optimization:
  cache_embeddings: true
  cache_ttl: 1800             # 30 minutes
  prefetch_size: 50           # Prefetch candidates
  
# Monitoring and logging
monitoring:
  log_retrieval_stats: true
  log_pipeline_timing: true
  track_query_patterns: false

# Advanced settings
advanced:
  # Query expansion
  query_expansion:
    enabled: false
    method: "synonyms"         # Options: synonyms, embeddings
    max_expansions: 3
  
  # Result diversification
  diversification:
    enabled: false
    method: "mmr"              # Maximal Marginal Relevance
    lambda_param: 0.7          # Balance between relevance and diversity
  
  # Custom scoring
  custom_scoring:
    enabled: false
    boost_recent: false        # Boost more recent documents
    boost_popular: false       # Boost popular documents
    
# Error handling
error_handling:
  fallback_to_dense: true      # If hybrid fails, use dense only
  max_retries: 3               # Retry attempts for failed queries
  timeout_seconds: 30          # Query timeout

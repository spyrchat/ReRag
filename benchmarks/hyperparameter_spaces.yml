# AutoRAG Hyperparameter Search Spaces
# This file defines different search spaces for optimizing RAG components

# Grid search example - explores all combinations
grid_search_space:
  search_type: grid
  description: "Comprehensive grid search over key RAG parameters"
  parameters:
    # Retrieval parameters
    benchmark.retrieval.top_k: [10, 20, 50, 100]
    benchmark.retrieval.search_params.score_threshold: [0.0, 0.1, 0.2, 0.3]
    benchmark.retrieval.strategy: ["dense", "hybrid", "sparse"]
    
    # Reranking parameters
    reranker.enabled: [true, false]
    reranker.top_k: [5, 10, 15, 20]
    reranker.model_name: ["cross-encoder/ms-marco-MiniLM-L-6-v2", "cross-encoder/ms-marco-TinyBERT-L-2-v2"]
    
    # Embedding parameters
    embedding.chunk_size: [256, 512, 1024]
    embedding.chunk_overlap: [50, 100, 200]

---

# Random search example - samples from continuous/discrete distributions
random_search_space:
  search_type: random
  n_random_arms: 100
  description: "Random sampling for efficient exploration"
  parameters:
    # Continuous parameters
    benchmark.retrieval.search_params.score_threshold:
      type: uniform
      low: 0.0
      high: 0.5
    
    # Discrete choices
    benchmark.retrieval.top_k: [5, 10, 20, 30, 50, 75, 100]
    benchmark.retrieval.strategy: ["dense", "hybrid", "sparse"]
    
    # Log-uniform for learning rates, etc.
    reranker.learning_rate:
      type: log_uniform
      low: 0.0001
      high: 0.01
    
    embedding.chunk_size: [128, 256, 512, 1024, 2048]
    embedding.chunk_overlap: [25, 50, 100, 150, 200, 300]

---

# Predefined configurations - uses your existing benchmark scenarios
predefined_search_space:
  search_type: predefined
  description: "Optimize over existing benchmark scenarios"
  predefined_configs:
    - name: "dense_baseline"
      parameters:
        benchmark:
          retrieval:
            strategy: "dense"
            top_k: 20
            search_params:
              score_threshold: 0.0
        reranker:
          enabled: false
    
    - name: "hybrid_advanced"
      parameters:
        benchmark:
          retrieval:
            strategy: "hybrid"
            top_k: 50
            search_params:
              score_threshold: 0.1
        reranker:
          enabled: true
          top_k: 10
          model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    
    - name: "sparse_bm25"
      parameters:
        benchmark:
          retrieval:
            strategy: "sparse"
            top_k: 100
            search_params:
              score_threshold: 0.0
        reranker:
          enabled: true
          top_k: 20

---

# Component-specific optimization spaces
retrieval_focused_space:
  search_type: grid
  description: "Focus on retrieval component optimization"
  parameters:
    benchmark.retrieval.top_k: [5, 10, 15, 20, 30, 40, 50, 75, 100]
    benchmark.retrieval.search_params.score_threshold: [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]
    benchmark.retrieval.strategy: ["dense", "hybrid", "sparse"]

reranking_focused_space:
  search_type: grid
  description: "Focus on reranking component optimization"
  parameters:
    reranker.enabled: [true]
    reranker.top_k: [3, 5, 8, 10, 15, 20, 25, 30]
    reranker.model_name: 
      - "cross-encoder/ms-marco-MiniLM-L-6-v2"
      - "cross-encoder/ms-marco-TinyBERT-L-2-v2"
      - "cross-encoder/ms-marco-MiniLM-L-12-v2"
    reranker.batch_size: [8, 16, 32, 64]

embedding_focused_space:
  search_type: random
  n_random_arms: 50
  description: "Focus on embedding and chunking optimization"
  parameters:
    embedding.chunk_size: [128, 256, 384, 512, 768, 1024, 1536, 2048]
    embedding.chunk_overlap: [0, 25, 50, 75, 100, 150, 200, 300]
    embedding.embedding_model: 
      - "sentence-transformers/all-MiniLM-L6-v2"
      - "sentence-transformers/all-mpnet-base-v2"
      - "text-embedding-ada-002"
